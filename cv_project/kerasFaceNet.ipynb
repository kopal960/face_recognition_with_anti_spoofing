{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from numpy import expand_dims\n",
    "import glob\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file management\n",
    "for i in range(1,10):\n",
    "    if str(i) not in os.listdir(os.getcwd()+\"/train\"):\n",
    "        os.mkdir(\"train/{x}\".format(x=i))\n",
    "    if str(i) not in os.listdir(os.getcwd()+\"/test\"):\n",
    "        os.mkdir(\"test/{x}\".format(x=i))\n",
    "    for c in random.sample(glob.glob(os.getcwd()+\"/WMCA small set/train/bonafied/b_00{x}*\".format(x=i)),50):\n",
    "        shutil.move(c , \"train/{x}\".format(x=i))\n",
    "    for c in random.sample(glob.glob(os.getcwd()+\"/WMCA small set/train/bonafied/b_00{x}*\".format(x=i)),20):\n",
    "        shutil.move(c , \"test/{x}\".format(x=i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<KerasTensor: shape=(None, 160, 160, 3) dtype=float32 (created by layer 'input_1')>]\n",
      "[<KerasTensor: shape=(None, 128) dtype=float32 (created by layer 'Bottleneck_BatchNorm')>]\n",
      "Model: \"inception_resnet_v1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 160, 160, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_1a_3x3 (Conv2D)          (None, 79, 79, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_1a_3x3_BatchNorm (BatchN (None, 79, 79, 32)   96          Conv2d_1a_3x3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_1a_3x3_Activation (Activ (None, 79, 79, 32)   0           Conv2d_1a_3x3_BatchNorm[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_2a_3x3 (Conv2D)          (None, 77, 77, 32)   9216        Conv2d_1a_3x3_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_2a_3x3_BatchNorm (BatchN (None, 77, 77, 32)   96          Conv2d_2a_3x3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_2a_3x3_Activation (Activ (None, 77, 77, 32)   0           Conv2d_2a_3x3_BatchNorm[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_2b_3x3 (Conv2D)          (None, 77, 77, 64)   18432       Conv2d_2a_3x3_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_2b_3x3_BatchNorm (BatchN (None, 77, 77, 64)   192         Conv2d_2b_3x3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_2b_3x3_Activation (Activ (None, 77, 77, 64)   0           Conv2d_2b_3x3_BatchNorm[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "MaxPool_3a_3x3 (MaxPooling2D)   (None, 38, 38, 64)   0           Conv2d_2b_3x3_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_3b_1x1 (Conv2D)          (None, 38, 38, 80)   5120        MaxPool_3a_3x3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_3b_1x1_BatchNorm (BatchN (None, 38, 38, 80)   240         Conv2d_3b_1x1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_3b_1x1_Activation (Activ (None, 38, 38, 80)   0           Conv2d_3b_1x1_BatchNorm[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_4a_3x3 (Conv2D)          (None, 36, 36, 192)  138240      Conv2d_3b_1x1_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_4a_3x3_BatchNorm (BatchN (None, 36, 36, 192)  576         Conv2d_4a_3x3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_4a_3x3_Activation (Activ (None, 36, 36, 192)  0           Conv2d_4a_3x3_BatchNorm[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_4b_3x3 (Conv2D)          (None, 17, 17, 256)  442368      Conv2d_4a_3x3_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_4b_3x3_BatchNorm (BatchN (None, 17, 17, 256)  768         Conv2d_4b_3x3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv2d_4b_3x3_Activation (Activ (None, 17, 17, 256)  0           Conv2d_4b_3x3_BatchNorm[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Conv2d_4b_3x3_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_1_Branch_2_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_1_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Conv2d_4b_3x3_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_1_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_1_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_1_Branch_2_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_1_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_1_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Conv2d_4b_3x3_Activation[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_1_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_1_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_1_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_1_Branch_1_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_1_Branch_2_Conv2d_0c_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_1_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_1_Branch_1_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_1_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_1_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block35_1_Branch_1_Conv2d_0b_3x3_\n",
      "                                                                 Block35_1_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_1_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Conv2d_4b_3x3_Activation[0][0]   \n",
      "                                                                 Block35_1_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_1_Activation (Activatio (None, 17, 17, 256)  0           Block35_1_ScaleSum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_1_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_2_Branch_2_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_2_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_1_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_2_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_2_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_2_Branch_2_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_2_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_2_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_1_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_2_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_2_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_2_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_2_Branch_1_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_2_Branch_2_Conv2d_0c_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_2_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_2_Branch_1_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_2_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_2_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block35_2_Branch_1_Conv2d_0b_3x3_\n",
      "                                                                 Block35_2_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_2_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_1_Activation[0][0]       \n",
      "                                                                 Block35_2_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_2_Activation (Activatio (None, 17, 17, 256)  0           Block35_2_ScaleSum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_2_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_3_Branch_2_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_3_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_2_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_3_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_3_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_3_Branch_2_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_3_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_3_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_2_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_3_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_3_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_3_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_3_Branch_1_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_3_Branch_2_Conv2d_0c_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_3_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_3_Branch_1_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_3_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_3_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block35_3_Branch_1_Conv2d_0b_3x3_\n",
      "                                                                 Block35_3_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_3_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_2_Activation[0][0]       \n",
      "                                                                 Block35_3_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_3_Activation (Activatio (None, 17, 17, 256)  0           Block35_3_ScaleSum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_3_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_4_Branch_2_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_4_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_3_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_4_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_4_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_4_Branch_2_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_4_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_4_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_3_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_4_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_4_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_4_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_4_Branch_1_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_4_Branch_2_Conv2d_0c_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_4_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_4_Branch_1_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_4_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_4_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block35_4_Branch_1_Conv2d_0b_3x3_\n",
      "                                                                 Block35_4_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_4_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_3_Activation[0][0]       \n",
      "                                                                 Block35_4_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_4_Activation (Activatio (None, 17, 17, 256)  0           Block35_4_ScaleSum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_4_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_5_Branch_2_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_5_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_4_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_5_Branch_2_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_5_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_5_Branch_2_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_5_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_5_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_4_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_5_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_5_Branch_2_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_5_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_5_Branch_1_Conv2d_0b_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_5_Branch_2_Conv2d_0c_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_5_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_5_Branch_1_Conv2d_0b_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_5_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_5_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block35_5_Branch_1_Conv2d_0b_3x3_\n",
      "                                                                 Block35_5_Branch_2_Conv2d_0c_3x3_\n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_5_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_4_Activation[0][0]       \n",
      "                                                                 Block35_5_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block35_5_Activation (Activatio (None, 17, 17, 256)  0           Block35_5_ScaleSum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_0a_1x1 (None, 17, 17, 192)  49152       Block35_5_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_0a_1x1 (None, 17, 17, 192)  576         Mixed_6a_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_0a_1x1 (None, 17, 17, 192)  0           Mixed_6a_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_0b_3x3 (None, 17, 17, 192)  331776      Mixed_6a_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_0b_3x3 (None, 17, 17, 192)  576         Mixed_6a_Branch_1_Conv2d_0b_3x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_0b_3x3 (None, 17, 17, 192)  0           Mixed_6a_Branch_1_Conv2d_0b_3x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_0_Conv2d_1a_3x3 (None, 8, 8, 384)    884736      Block35_5_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_1a_3x3 (None, 8, 8, 256)    442368      Mixed_6a_Branch_1_Conv2d_0b_3x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_0_Conv2d_1a_3x3 (None, 8, 8, 384)    1152        Mixed_6a_Branch_0_Conv2d_1a_3x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_1a_3x3 (None, 8, 8, 256)    768         Mixed_6a_Branch_1_Conv2d_1a_3x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_0_Conv2d_1a_3x3 (None, 8, 8, 384)    0           Mixed_6a_Branch_0_Conv2d_1a_3x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_1_Conv2d_1a_3x3 (None, 8, 8, 256)    0           Mixed_6a_Branch_1_Conv2d_1a_3x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a_Branch_2_MaxPool_1a_3x (None, 8, 8, 256)    0           Block35_5_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_6a (Concatenate)          (None, 8, 8, 896)    0           Mixed_6a_Branch_0_Conv2d_1a_3x3_A\n",
      "                                                                 Mixed_6a_Branch_1_Conv2d_1a_3x3_A\n",
      "                                                                 Mixed_6a_Branch_2_MaxPool_1a_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_1_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_1_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_1_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_1_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_1_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_1_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_1_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_1_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_1_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_1_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_1_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_1_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_1_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Mixed_6a[0][0]                   \n",
      "                                                                 Block17_1_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_1_Activation (Activatio (None, 8, 8, 896)    0           Block17_1_ScaleSum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_1_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_2_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_2_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_2_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_2_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_2_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_1_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_2_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_2_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_2_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_2_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_2_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_2_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_2_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_2_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_1_Activation[0][0]       \n",
      "                                                                 Block17_2_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_2_Activation (Activatio (None, 8, 8, 896)    0           Block17_2_ScaleSum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_2_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_3_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_3_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_3_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_3_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_3_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_2_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_3_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_3_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_3_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_3_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_3_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_3_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_3_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_3_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_2_Activation[0][0]       \n",
      "                                                                 Block17_3_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_3_Activation (Activatio (None, 8, 8, 896)    0           Block17_3_ScaleSum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_3_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_4_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_4_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_4_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_4_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_4_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_3_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_4_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_4_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_4_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_4_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_4_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_4_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_4_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_4_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_3_Activation[0][0]       \n",
      "                                                                 Block17_4_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_4_Activation (Activatio (None, 8, 8, 896)    0           Block17_4_ScaleSum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_4_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_5_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_5_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_5_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_5_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_5_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_4_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_5_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_5_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_5_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_5_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_5_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_5_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_5_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_5_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_4_Activation[0][0]       \n",
      "                                                                 Block17_5_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_5_Activation (Activatio (None, 8, 8, 896)    0           Block17_5_ScaleSum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_5_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_6_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_6_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_6_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_6_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_6_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_5_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_6_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_6_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_6_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_6_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_6_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_6_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_6_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_6_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_5_Activation[0][0]       \n",
      "                                                                 Block17_6_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_6_Activation (Activatio (None, 8, 8, 896)    0           Block17_6_ScaleSum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_6_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_7_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_7_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_7_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_7_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_7_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_6_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_7_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_7_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_7_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_7_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_7_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_7_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_7_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_7_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_6_Activation[0][0]       \n",
      "                                                                 Block17_7_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_7_Activation (Activatio (None, 8, 8, 896)    0           Block17_7_ScaleSum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_7_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_8_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_8_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_8_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_8_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_8_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_7_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_8_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_8_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_8_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_8_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_8_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_8_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_8_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_8_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_7_Activation[0][0]       \n",
      "                                                                 Block17_8_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_8_Activation (Activatio (None, 8, 8, 896)    0           Block17_8_ScaleSum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_8_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_9_Branch_1_Conv2d_0a_1x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_9_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_9_Branch_1_Conv2d_0a_1x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_9_Branch_1_Conv2d_0b_1x7[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_9_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_8_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_9_Branch_1_Conv2d_0b_1x7_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_9_Branch_0_Conv2d_1x1[0][\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_9_Branch_1_Conv2d_0c_7x1[\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_9_Branch_0_Conv2d_1x1_Bat\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_9_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_9_Branch_0_Conv2d_1x1_Act\n",
      "                                                                 Block17_9_Branch_1_Conv2d_0c_7x1_\n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_9_Concatenate[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_8_Activation[0][0]       \n",
      "                                                                 Block17_9_Conv2d_1x1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_9_Activation (Activatio (None, 8, 8, 896)    0           Block17_9_ScaleSum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0a_1 (None, 8, 8, 128)    114688      Block17_9_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0a_1 (None, 8, 8, 128)    384         Block17_10_Branch_1_Conv2d_0a_1x1\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0a_1 (None, 8, 8, 128)    0           Block17_10_Branch_1_Conv2d_0a_1x1\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0b_1 (None, 8, 8, 128)    114688      Block17_10_Branch_1_Conv2d_0a_1x1\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0b_1 (None, 8, 8, 128)    384         Block17_10_Branch_1_Conv2d_0b_1x7\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0b_1 (None, 8, 8, 128)    0           Block17_10_Branch_1_Conv2d_0b_1x7\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_0_Conv2d_1x1  (None, 8, 8, 128)    114688      Block17_9_Activation[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0c_7 (None, 8, 8, 128)    114688      Block17_10_Branch_1_Conv2d_0b_1x7\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_0_Conv2d_1x1_ (None, 8, 8, 128)    384         Block17_10_Branch_0_Conv2d_1x1[0]\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0c_7 (None, 8, 8, 128)    384         Block17_10_Branch_1_Conv2d_0c_7x1\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_0_Conv2d_1x1_ (None, 8, 8, 128)    0           Block17_10_Branch_0_Conv2d_1x1_Ba\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Branch_1_Conv2d_0c_7 (None, 8, 8, 128)    0           Block17_10_Branch_1_Conv2d_0c_7x1\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Concatenate (Concate (None, 8, 8, 256)    0           Block17_10_Branch_0_Conv2d_1x1_Ac\n",
      "                                                                 Block17_10_Branch_1_Conv2d_0c_7x1\n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Conv2d_1x1 (Conv2D)  (None, 8, 8, 896)    230272      Block17_10_Concatenate[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_ScaleSum (Lambda)    (None, 8, 8, 896)    0           Block17_9_Activation[0][0]       \n",
      "                                                                 Block17_10_Conv2d_1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Block17_10_Activation (Activati (None, 8, 8, 896)    0           Block17_10_ScaleSum[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_0a_1x1 (None, 8, 8, 256)    229376      Block17_10_Activation[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_0a_1x1 (None, 8, 8, 256)    768         Mixed_7a_Branch_2_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_0a_1x1 (None, 8, 8, 256)    0           Mixed_7a_Branch_2_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_0_Conv2d_0a_1x1 (None, 8, 8, 256)    229376      Block17_10_Activation[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_1_Conv2d_0a_1x1 (None, 8, 8, 256)    229376      Block17_10_Activation[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_0b_3x3 (None, 8, 8, 256)    589824      Mixed_7a_Branch_2_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_0_Conv2d_0a_1x1 (None, 8, 8, 256)    768         Mixed_7a_Branch_0_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_1_Conv2d_0a_1x1 (None, 8, 8, 256)    768         Mixed_7a_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_0b_3x3 (None, 8, 8, 256)    768         Mixed_7a_Branch_2_Conv2d_0b_3x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_0_Conv2d_0a_1x1 (None, 8, 8, 256)    0           Mixed_7a_Branch_0_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_1_Conv2d_0a_1x1 (None, 8, 8, 256)    0           Mixed_7a_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_0b_3x3 (None, 8, 8, 256)    0           Mixed_7a_Branch_2_Conv2d_0b_3x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_0_Conv2d_1a_3x3 (None, 3, 3, 384)    884736      Mixed_7a_Branch_0_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_1_Conv2d_1a_3x3 (None, 3, 3, 256)    589824      Mixed_7a_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_1a_3x3 (None, 3, 3, 256)    589824      Mixed_7a_Branch_2_Conv2d_0b_3x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_0_Conv2d_1a_3x3 (None, 3, 3, 384)    1152        Mixed_7a_Branch_0_Conv2d_1a_3x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_1_Conv2d_1a_3x3 (None, 3, 3, 256)    768         Mixed_7a_Branch_1_Conv2d_1a_3x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_1a_3x3 (None, 3, 3, 256)    768         Mixed_7a_Branch_2_Conv2d_1a_3x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_0_Conv2d_1a_3x3 (None, 3, 3, 384)    0           Mixed_7a_Branch_0_Conv2d_1a_3x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_1_Conv2d_1a_3x3 (None, 3, 3, 256)    0           Mixed_7a_Branch_1_Conv2d_1a_3x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_2_Conv2d_1a_3x3 (None, 3, 3, 256)    0           Mixed_7a_Branch_2_Conv2d_1a_3x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a_Branch_3_MaxPool_1a_3x (None, 3, 3, 896)    0           Block17_10_Activation[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Mixed_7a (Concatenate)          (None, 3, 3, 1792)   0           Mixed_7a_Branch_0_Conv2d_1a_3x3_A\n",
      "                                                                 Mixed_7a_Branch_1_Conv2d_1a_3x3_A\n",
      "                                                                 Mixed_7a_Branch_2_Conv2d_1a_3x3_A\n",
      "                                                                 Mixed_7a_Branch_3_MaxPool_1a_3x3[\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_1_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_1_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_1_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_1_Branch_1_Conv2d_0b_1x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_1_Branch_1_Conv2d_0b_1x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_1_Branch_1_Conv2d_0b_1x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_1_Branch_0_Conv2d_1x1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_1_Branch_1_Conv2d_0c_3x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_1_Branch_0_Conv2d_1x1_Batc\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_1_Branch_1_Conv2d_0c_3x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_1_Branch_0_Conv2d_1x1_Acti\n",
      "                                                                 Block8_1_Branch_1_Conv2d_0c_3x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_1_Concatenate[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Mixed_7a[0][0]                   \n",
      "                                                                 Block8_1_Conv2d_1x1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_1_Activation (Activation (None, 3, 3, 1792)   0           Block8_1_ScaleSum[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_1_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_2_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_2_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_2_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_2_Branch_1_Conv2d_0b_1x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_2_Branch_1_Conv2d_0b_1x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_1_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_2_Branch_1_Conv2d_0b_1x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_2_Branch_0_Conv2d_1x1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_2_Branch_1_Conv2d_0c_3x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_2_Branch_0_Conv2d_1x1_Batc\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_2_Branch_1_Conv2d_0c_3x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_2_Branch_0_Conv2d_1x1_Acti\n",
      "                                                                 Block8_2_Branch_1_Conv2d_0c_3x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_2_Concatenate[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_1_Activation[0][0]        \n",
      "                                                                 Block8_2_Conv2d_1x1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_2_Activation (Activation (None, 3, 3, 1792)   0           Block8_2_ScaleSum[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_2_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_3_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_3_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_3_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_3_Branch_1_Conv2d_0b_1x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_3_Branch_1_Conv2d_0b_1x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_2_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_3_Branch_1_Conv2d_0b_1x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_3_Branch_0_Conv2d_1x1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_3_Branch_1_Conv2d_0c_3x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_3_Branch_0_Conv2d_1x1_Batc\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_3_Branch_1_Conv2d_0c_3x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_3_Branch_0_Conv2d_1x1_Acti\n",
      "                                                                 Block8_3_Branch_1_Conv2d_0c_3x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_3_Concatenate[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_2_Activation[0][0]        \n",
      "                                                                 Block8_3_Conv2d_1x1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_3_Activation (Activation (None, 3, 3, 1792)   0           Block8_3_ScaleSum[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_3_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_4_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_4_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_4_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_4_Branch_1_Conv2d_0b_1x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_4_Branch_1_Conv2d_0b_1x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_3_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_4_Branch_1_Conv2d_0b_1x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_4_Branch_0_Conv2d_1x1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_4_Branch_1_Conv2d_0c_3x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_4_Branch_0_Conv2d_1x1_Batc\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_4_Branch_1_Conv2d_0c_3x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_4_Branch_0_Conv2d_1x1_Acti\n",
      "                                                                 Block8_4_Branch_1_Conv2d_0c_3x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_4_Concatenate[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_3_Activation[0][0]        \n",
      "                                                                 Block8_4_Conv2d_1x1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_4_Activation (Activation (None, 3, 3, 1792)   0           Block8_4_ScaleSum[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_4_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_5_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_5_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_5_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_5_Branch_1_Conv2d_0b_1x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_5_Branch_1_Conv2d_0b_1x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_4_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_5_Branch_1_Conv2d_0b_1x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_5_Branch_0_Conv2d_1x1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_5_Branch_1_Conv2d_0c_3x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_5_Branch_0_Conv2d_1x1_Batc\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_5_Branch_1_Conv2d_0c_3x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_5_Branch_0_Conv2d_1x1_Acti\n",
      "                                                                 Block8_5_Branch_1_Conv2d_0c_3x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_5_Concatenate[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_4_Activation[0][0]        \n",
      "                                                                 Block8_5_Conv2d_1x1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_5_Activation (Activation (None, 3, 3, 1792)   0           Block8_5_ScaleSum[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_5_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_6_Branch_1_Conv2d_0a_1x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_6_Branch_1_Conv2d_0a_1x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_6_Branch_1_Conv2d_0a_1x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_6_Branch_1_Conv2d_0b_1x3[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_6_Branch_1_Conv2d_0b_1x3_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_5_Activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_6_Branch_1_Conv2d_0b_1x3_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_6_Branch_0_Conv2d_1x1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_6_Branch_1_Conv2d_0c_3x1[0\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_6_Branch_0_Conv2d_1x1_Batc\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_6_Branch_1_Conv2d_0c_3x1_B\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_6_Branch_0_Conv2d_1x1_Acti\n",
      "                                                                 Block8_6_Branch_1_Conv2d_0c_3x1_A\n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_6_Concatenate[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Block8_6_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_5_Activation[0][0]        \n",
      "                                                                 Block8_6_Conv2d_1x1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "AvgPool (GlobalAveragePooling2D (None, 1792)         0           Block8_6_ScaleSum[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Dropout (Dropout)               (None, 1792)         0           AvgPool[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Bottleneck (Dense)              (None, 128)          229376      Dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Bottleneck_BatchNorm (BatchNorm (None, 128)          384         Bottleneck[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 22,808,144\n",
      "Trainable params: 22,779,312\n",
      "Non-trainable params: 28,832\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# example of loading the keras facenet model\n",
    "from keras.models import load_model\n",
    "# load the model\n",
    "#model = load_model('facenet_keras.h5')\n",
    "# summarize input and output shape\n",
    "print(model.inputs)\n",
    "print(model.outputs)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(img):\n",
    "    #convert the test image to gray scale as opencv face detector expects gray images\n",
    "    gray = img\n",
    " \n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_alt.xml')\n",
    "\n",
    "    #let's detect multiscale images(some images may be closer to camera than others)\n",
    "    #result is a list of faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5);\n",
    "\n",
    "    #if no faces are detected then return original img\n",
    "    if (len(faces) == 0):\n",
    "        return None, None\n",
    "\n",
    "    #under the assumption that there will be only one face,\n",
    "    #extract the face area\n",
    "    (x, y, w, h) = faces[0]\n",
    "    \n",
    "    face_img = gray[y:y+w , x:x+h]\n",
    "    image = Image.fromarray(face_img)\n",
    "    image = image.resize((160,160))\n",
    "    face_img = asarray(image)\n",
    "\n",
    "    #return only the face part of the image\n",
    "    return face_img, faces[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(data_folder_path):\n",
    " \n",
    "    #------STEP-1--------\n",
    "    #get the directories (one directory for each subject) in data folder\n",
    "    dirs = os.listdir(data_folder_path)\n",
    "\n",
    "    #list to hold all subject faces\n",
    "    faces = []\n",
    "    #list to hold labels for all subjects\n",
    "    labels = []\n",
    "\n",
    "    #let's go through each directory and read images within it\n",
    "    for dir_name in dirs:\n",
    "\n",
    "        #------STEP-2--------\n",
    "        #extract label number of subject from dir_name\n",
    "        #format of dir name = slabel\n",
    "        #, so removing letter 's' from dir_name will give us label\n",
    "        label = int(dir_name)\n",
    "\n",
    "        #build path of directory containing images for current subject subject\n",
    "        #sample subject_dir_path = \"training-data/s1\"\n",
    "        subject_dir_path = data_folder_path + \"/\" + dir_name\n",
    "\n",
    "        #get the images names that are inside the given subject directory\n",
    "        subject_images_names = os.listdir(subject_dir_path)\n",
    "        #print(len(subject_images_names))\n",
    "\n",
    "        #------STEP-3--------\n",
    "        #go through each image name, read image, \n",
    "        #detect face and add face to list of faces\n",
    "        count = 0\n",
    "        for image_name in subject_images_names:\n",
    "            #build image path\n",
    "            #sample image path = training-data/s1/1.pgm\n",
    "            image_path = subject_dir_path + \"/\" + image_name\n",
    "\n",
    "            #read image\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "\n",
    "            #detect face\n",
    "            face, rect = detect_face(image)\n",
    "\n",
    "            #------STEP-4--------\n",
    "            #for the purpose of this tutorial\n",
    "            #we will ignore faces that are not detected\n",
    "            if face is not None:\n",
    "                #display an image window to show the image \n",
    "                cv2.imshow(\"Training on image...\", face)\n",
    "                cv2.waitKey(100)\n",
    "                #add face to list of faces\n",
    "                faces.append(face)\n",
    "                #add label for this face\n",
    "                labels.append(label)\n",
    "                count = count+1\n",
    "        print(count)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    cv2.waitKey(1)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return faces, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "48\n",
      "39\n",
      "49\n",
      "45\n",
      "15\n",
      "16\n",
      "27\n",
      "18\n",
      "27\n",
      "20\n",
      "14\n",
      "19\n",
      "16\n",
      "6\n",
      "4\n",
      "14\n",
      "6\n",
      "11\n",
      "Data prepared\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing data...\")\n",
    "facesTrain, trainY = prepare_training_data(\"train\")\n",
    "facesTest , testY = prepare_training_data(\"test\")\n",
    "print(\"Data prepared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001CDCF8E6318> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCF8E6318>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000001CDCF8E6318> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCF8E6318>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001CDCF8E6438> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCF8E6438>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000001CDCF8E6438> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCF8E6438>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001CDCF8E6168> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCF8E6168>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000001CDCF8E6168> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCF8E6168>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001CDCF8E64C8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCF8E64C8>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000001CDCF8E64C8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCF8E64C8>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001CDCF8E6678> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCF8E6678>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000001CDCF8E6678> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCF8E6678>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001CDCF8E6798> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCF8E6798>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000001CDCF8E6798> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCF8E6798>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001CDCF8E68B8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCF8E68B8>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000001CDCF8E68B8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCF8E68B8>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001CDCF8E69D8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCF8E69D8>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000001CDCF8E69D8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCF8E69D8>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001CDCF8E6AF8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCF8E6AF8>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000001CDCF8E6AF8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCF8E6AF8>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001CDCF8E6C18> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCF8E6C18>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000001CDCF8E6C18> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCF8E6C18>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001CDCF8E6D38> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCF8E6D38>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000001CDCF8E6D38> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCF8E6D38>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001CDCF8E6E58> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCF8E6E58>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000001CDCF8E6E58> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCF8E6E58>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001CDCF8E6F78> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCF8E6F78>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000001CDCF8E6F78> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCF8E6F78>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001CDCFA5E0D8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCFA5E0D8>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000001CDCFA5E0D8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCFA5E0D8>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001CDCFA5E1F8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCFA5E1F8>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000001CDCFA5E1F8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCFA5E1F8>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001CDCFA5E288> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCFA5E288>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000001CDCFA5E288> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCFA5E288>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001CDCFA5E438> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCFA5E438>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000001CDCFA5E438> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCFA5E438>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001CDCFA5E558> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCFA5E558>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000001CDCFA5E558> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCFA5E558>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001CDCFA5E678> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCFA5E678>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000001CDCFA5E678> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCFA5E678>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001CDCFA5E798> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCFA5E798>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000001CDCFA5E798> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCFA5E798>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001CDCFA5E8B8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCFA5E8B8>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000001CDCFA5E8B8> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000001CDCFA5E8B8>: no matching AST found\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "(110, 128)\n"
     ]
    }
   ],
   "source": [
    "def get_embedding(model, face_pixels):\n",
    "    # scale pixel values\n",
    "    face_pixels = face_pixels.astype('float32')\n",
    "    # standardize pixel values across channels (global)\n",
    "    mean, std = face_pixels.mean(), face_pixels.std()\n",
    "    face_pixels = (face_pixels - mean) / std\n",
    "    # transform face into one sample\n",
    "    samples = expand_dims(face_pixels, axis=0)\n",
    "    # make prediction to get embedding\n",
    "    yhat = model.predict(samples)\n",
    "    return yhat[0]\n",
    "\n",
    "newTrainX = []\n",
    "for face in facesTrain:\n",
    "    embedding = get_embedding(model, face)\n",
    "    newTrainX.append(embedding)\n",
    "newTrainX = asarray(newTrainX)\n",
    " \n",
    "newTestX = []\n",
    "for face in facesTest:\n",
    "    embedding = get_embedding(model, face)\n",
    "    newTestX.append(embedding)\n",
    "newTestX = asarray(newTestX)\n",
    "print(newTestX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 128)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newTrainX = asarray(newTrainX)\n",
    "newTestX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# develop a classifier for the 5 Celebrity Faces Dataset\n",
    "from random import choice\n",
    "from numpy import load\n",
    "from numpy import expand_dims\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_encoder = Normalizer(norm='l2')\n",
    "trainX = in_encoder.transform(newTrainX)\n",
    "testX = in_encoder.transform(newTestX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encode targets\n",
    "out_encoder = LabelEncoder()\n",
    "out_encoder.fit(trainY)\n",
    "trainy = out_encoder.transform(trainY)\n",
    "testy = out_encoder.transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
       "        5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8,\n",
       "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8],\n",
       "       dtype=int64),\n",
       " [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainy , trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(trainX, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: train=100.000, test=100.000\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "yhat_train = model.predict(trainX)\n",
    "yhat_test = model.predict(testX)\n",
    "# score\n",
    "score_train = accuracy_score(trainy, yhat_train)\n",
    "score_test = accuracy_score(testy, yhat_test)\n",
    "# summarize\n",
    "print('Accuracy: train=%.3f, test=%.3f' % (score_train*100, score_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((57, 128), (57,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX.shape , testy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#restore\n",
    "for c in glob.glob(\"train/*/*\"):\n",
    "    shutil.move(c, \"WMCA small set/train/bonafied\")\n",
    "for c in glob.glob(\"test/*/*\"):\n",
    "    shutil.move(c, \"WMCA small set/train/bonafied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8,\n",
       "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8],\n",
       "       dtype=int64),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8,\n",
       "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8],\n",
       "       dtype=int64))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fr",
   "language": "python",
   "name": "fr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
