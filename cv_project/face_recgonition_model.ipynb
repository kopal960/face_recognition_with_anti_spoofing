{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 360 images belonging to 9 classes.\n",
      "Found 36 images belonging to 9 classes.\n",
      "<keras.preprocessing.image.DirectoryIterator object at 0x000002686C1AFC88>\n",
      "{'1': 0, '2': 1, '3': 2, '4': 3, '5': 4, '6': 5, '7': 6, '8': 7, '9': 8}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 5, 5, 32)          368672    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 5, 5, 32)          0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 32)               0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 297       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,626,953\n",
      "Trainable params: 368,969\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n",
      "Number of trainable variables = 4\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026878FD70D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000026878FD70D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.3354 - accuracy: 0.5306WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026804223AF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000026804223AF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "72/72 [==============================] - 23s 206ms/step - loss: 1.3354 - accuracy: 0.5306 - val_loss: 0.6394 - val_accuracy: 0.6667\n",
      "Epoch 2/10\n",
      "72/72 [==============================] - 13s 175ms/step - loss: 0.4084 - accuracy: 0.8278 - val_loss: 0.1797 - val_accuracy: 0.9722\n",
      "Epoch 3/10\n",
      "72/72 [==============================] - 13s 178ms/step - loss: 0.0591 - accuracy: 0.9889 - val_loss: 0.0320 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "72/72 [==============================] - 13s 179ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "72/72 [==============================] - 13s 176ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9722\n",
      "Epoch 6/10\n",
      "72/72 [==============================] - 12s 170ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "72/72 [==============================] - 12s 167ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "72/72 [==============================] - 13s 174ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "72/72 [==============================] - 12s 172ms/step - loss: 9.2946e-04 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "72/72 [==============================] - 12s 170ms/step - loss: 7.6947e-04 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  154\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 5, 5, 32)          368672    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 5, 5, 32)          0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 32)               0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 297       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,626,953\n",
      "Trainable params: 2,230,409\n",
      "Non-trainable params: 396,544\n",
      "_________________________________________________________________\n",
      "Number of trainable variables = 58\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000268057BC288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000268057BC288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "72/72 [==============================] - ETA: 0s - loss: 3.8837 - accuracy: 0.4639WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002680B858DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002680B858DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "72/72 [==============================] - 33s 317ms/step - loss: 3.8837 - accuracy: 0.4639 - val_loss: 0.0713 - val_accuracy: 0.9722\n",
      "Epoch 2/5\n",
      "72/72 [==============================] - 20s 284ms/step - loss: 0.6602 - accuracy: 0.8056 - val_loss: 0.0391 - val_accuracy: 0.9722\n",
      "Epoch 3/5\n",
      "72/72 [==============================] - 21s 287ms/step - loss: 0.3866 - accuracy: 0.8944 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "72/72 [==============================] - 19s 266ms/step - loss: 0.3529 - accuracy: 0.8806 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "72/72 [==============================] - 21s 288ms/step - loss: 0.2268 - accuracy: 0.9333 - val_loss: 0.0034 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kopal\\Anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved to save/fine_tuning.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Summary:\\n* **Using a pre-trained model for feature extraction**:  When working with a small dataset, it is common to take advantage of features learned by a model trained on a larger dataset in the same domain. This is done by instantiating the pre-trained model and adding a fully-connected classifier on top. The pre-trained model is \"frozen\" and only the weights of the classifier get updated during training.\\nIn this case, the convolutional base extracted all the features associated with each image and you just trained a classifier that determines the image class given that set of extracted features.\\n\\n* **Fine-tuning a pre-trained model**: To further improve performance, one might want to repurpose the top-level layers of the pre-trained models to the new dataset via fine-tuning.\\nIn this case, you tuned your weights such that your model learned high-level features specific to the dataset. This technique is usually recommended when the training dataset is large and very similar to the orginial dataset that the pre-trained model was trained on.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "IMAGE_SIZE = 224\n",
    "\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    validation_split=0.2)\n",
    "\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "    \"C:/Users/kopal/Documents/face_recognition_with_anti_spoofing/face_recognition_with_anti_spoofing/cv_project/train\",\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    subset='training')\n",
    "\n",
    "val_generator = data_generator.flow_from_directory(\n",
    "    \"C:/Users/kopal/Documents/face_recognition_with_anti_spoofing/face_recognition_with_anti_spoofing/cv_project/test\",\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    subset='validation')\n",
    "\n",
    "print(val_generator)\n",
    "\n",
    "for image_batch, label_batch in train_generator:\n",
    "    break\n",
    "\n",
    "print(train_generator.class_indices)\n",
    "\n",
    "labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
    "\n",
    "with open('labels.txt', 'w') as f:\n",
    "    f.write(labels)\n",
    "\n",
    "IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add a classification head\n",
    "# We are going to add more classification 'heads' to our model\n",
    "\n",
    "# 1 -   We are giving our base model (Top Layer removed, hidden and output layer UN-TRAINABLE)\n",
    "\n",
    "# 2 -   2D Convolution network (32 nodes, 3 Kernel size, Activation Function)\n",
    "#       [Remember how Convolutions are formed, with role of kernels]\n",
    "#       [ Kernels in Convents are Odd numbered]\n",
    "#       [ Kernels are just a determinant which is multiplied with Image Matrix]\n",
    "#       [They help in enhancement of features]\n",
    "\n",
    "# 3 -   We don't need all nodes, 20% of nodes will be dropped out [probability of each \"bad\" node being dropped is 20%\n",
    "#       Bad here means the nodes which are not contributing much value to the final output\n",
    "\n",
    "# 4 -   Convolution and pooling - 2X2 matrix is taken and a pooling is done\n",
    "#       Pooling is done for data size reduction by taking average\n",
    "\n",
    "# 5 -   All above are transformation layers, this is the main Dense Layer\n",
    "#       Dense layer takes input from all prev nodes and gives input to all next nodes.\n",
    "#       It is very densely connected and hence called the Dense Layer.\n",
    "#       We are using the Activation function of 'Softmax'\n",
    "#       There is another popular Activation function called 'Relu'\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,  # 1\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),  # 2\n",
    "    tf.keras.layers.Dropout(0.2),  # 3\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),  # 4\n",
    "    tf.keras.layers.Dense(9, activation='softmax')  # 5\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),  # 1\n",
    "              loss='categorical_crossentropy',  # 2\n",
    "              metrics=['accuracy'])  # 3\n",
    "\n",
    "model.summary()\n",
    "\n",
    "print('Number of trainable variables = {}'.format(len(model.trainable_variables)))\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=val_generator)\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()), 1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0, 1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "\"\"\"## Fine tuning\n",
    "In our feature extraction experiment, you were only training a few layers on top of an MobileNet V2 base model. The weights of the pre-trained network were **not** updated during training.\n",
    "\n",
    "One way to increase performance even further is to train (or \"fine-tune\") the weights of the top layers of the pre-trained model alongside the training of the classifier you added. The training process will force the weights to be tuned from generic features maps to features associated specifically to our dataset.\n",
    "\n",
    "### Un-freeze the top layers of the model\n",
    "\n",
    "All you need to do is unfreeze the `base_model` and set the bottom layers be un-trainable. Then, recompile the model (necessary for these changes to take effect), and resume training.\n",
    "\"\"\"\n",
    "\n",
    "base_model.trainable = True\n",
    "\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "\n",
    "fine_tune_at = 100\n",
    "\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "print('Number of trainable variables = {}'.format(len(model.trainable_variables)))\n",
    "\n",
    "history_fine = model.fit(train_generator,\n",
    "                         epochs=5,\n",
    "                         validation_data=val_generator\n",
    "                         )\n",
    "\n",
    "saved_model_dir = 'fine_tuning.h5'\n",
    "model.save(saved_model_dir)\n",
    "print(\"Model Saved to save/fine_tuning.h5\")\n",
    "\n",
    "'''#tf.saved_model.save(model, saved_model_dir)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model_file(model)\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)'''\n",
    "\n",
    "\n",
    "\n",
    "acc = history_fine.history['accuracy']\n",
    "val_acc = history_fine.history['val_accuracy']\n",
    "\n",
    "loss = history_fine.history['loss']\n",
    "val_loss = history_fine.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()), 1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0, 1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "# Summary:\n",
    "* **Using a pre-trained model for feature extraction**:  When working with a small dataset, it is common to take advantage of features learned by a model trained on a larger dataset in the same domain. This is done by instantiating the pre-trained model and adding a fully-connected classifier on top. The pre-trained model is \"frozen\" and only the weights of the classifier get updated during training.\n",
    "In this case, the convolutional base extracted all the features associated with each image and you just trained a classifier that determines the image class given that set of extracted features.\n",
    "\n",
    "* **Fine-tuning a pre-trained model**: To further improve performance, one might want to repurpose the top-level layers of the pre-trained models to the new dataset via fine-tuning.\n",
    "In this case, you tuned your weights such that your model learned high-level features specific to the dataset. This technique is usually recommended when the training dataset is large and very similar to the orginial dataset that the pre-trained model was trained on.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 5, 5, 32)          368672    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 5, 5, 32)          0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 32)               0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 297       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,626,953\n",
      "Trainable params: 2,230,409\n",
      "Non-trainable params: 396,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(saved_model_dir)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "    if str(i) not in os.listdir(os.getcwd()+\"/train\"):\n",
    "        os.mkdir(\"train/{x}\".format(x=i))\n",
    "    if str(i) not in os.listdir(os.getcwd()+\"/test\"):\n",
    "        os.mkdir(\"test/{x}\".format(x=i))\n",
    "    for c in random.sample(glob.glob(os.getcwd()+\"/WMCA small set/train/bonafied/b_00{x}*\".format(x=i)),50):\n",
    "        shutil.move(c , \"train/{x}\".format(x=i))\n",
    "    for c in random.sample(glob.glob(os.getcwd()+\"/WMCA small set/train/bonafied/b_00{x}*\".format(x=i)),10):\n",
    "        shutil.move(c , \"test/{x}\".format(x=i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#restore\n",
    "for c in glob.glob(\"train/*/*\"):\n",
    "    shutil.move(c, \"WMCA small set/train/bonafied\")\n",
    "for c in glob.glob(\"test/*/*\"):\n",
    "    shutil.move(c, \"WMCA small set/train/bonafied\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_fr",
   "language": "python",
   "name": "cv_fr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
